{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5c791e1",
   "metadata": {},
   "source": [
    "# ðŸ›°ï¸ Shift-and-Stack Tutorial for Astronomical Image Processing\n",
    "\n",
    "This tutorial demonstrates how to apply the **shift-and-stack** technique to detect faint objects in CCD images.\n",
    "The method aligns multiple exposures based on predicted motion and co-adds them to increase signal-to-noise ratio (S/N).\n",
    "\n",
    "We will:\n",
    "- Read and clean CCD images\n",
    "- Use WCS to align based on known ephemerides\n",
    "- Apply cosmic ray rejection\n",
    "- Perform shift-and-stack using mean and median methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5fd65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astroquery.jplhorizons import Horizons\n",
    "import os, glob, scipy.signal as signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bcc729-4f01-40ae-bf89-aacea7098eb3",
   "metadata": {},
   "source": [
    "## Defining File Locations and the JPL Record ID\n",
    "\n",
    "We need to give the notebook the right directories to search when performing this analysis as well as the JPL Horizons Record ID for the specific orbital solution that we want to query. You can find that by searching the object on JPL Horizons and checking the 'Record ID' keyword in the output file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73eac8b-98a0-4814-8fea-af0b54265df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'directory for files to analyze'\n",
    "record_id = 'JPL Horizons orbit record ID to reduce errors when querying'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd4be22",
   "metadata": {},
   "source": [
    "## ðŸ”­ Correcting WCS Based on Known Star\n",
    "We first correct the World Coordinate System (WCS) so that all images align based on a reference star.\n",
    "This ensures the stacking step aligns the target object's motion properly. This option is not required, depending on the accuracy of the iamges existing WCS solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69e427e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_wcs_solutions():\n",
    "    drz_list = glob(location + '/science image folder')\n",
    "    #For each file in the drz list you'll need to find a reference star in each image, compare the RA and DEC of what's in the file to what\n",
    "    # is available from the catalogs, and put the delta here. As a default I've set everything to zero so you can run this step if you'd like.\n",
    "    shift_array = np.array([['ifed01pfq',0,0],\n",
    "                  ['ifed01pgq',0,0], \n",
    "                  ['ifed01phq',0,0],\n",
    "                  ['ifed01piq',0,0],\n",
    "                  ['ifed01pjq',0,0],\n",
    "                  ['ifed01pkq',0,0], \n",
    "                  ['ifed01plq',0,0],\n",
    "                  ['ifed01pmq',0,0]])\n",
    "    \n",
    "    for drz in drz_list:\n",
    "        print(drz)\n",
    "        shift_list = shift_array[shift_array[:,0]==drz[25:34]][0]\n",
    "        with fits.open(drz) as hdul:\n",
    "            wcs = WCS(hdul[1].header)\n",
    "            print(shift_list[1])\n",
    "            wcs.wcs.crpix += [int(shift_list[1]), int(shift_list[2])]\n",
    "            hdul[1].header.update(wcs.to_header())\n",
    "            hdul.writeto(drz[:-5]+'.fits',overwrite=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd800f4",
   "metadata": {},
   "source": [
    "## âœ¨ Cleaning the Images\n",
    "First, let's define a basic cosmic-ray rejection filter that replaces isolated bright pixels. There are other versions, like LACosmic, that you can check out, but this one is simple. For any given pixel on the detector, it searches the pixels around it to identify the median. If the center pixel is more than 15 times higher that the surroundings, that is interpreted as a cosmic ray and \"cleaned\" by assigning that pixel the median value. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9078e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_image(data_slice):\n",
    "    '''\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_slice : 2D image array or IFU slice\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    clean_slice : 2D image array or IFU slice with cosmic rays remove\n",
    "\n",
    "    '''\n",
    "    #Takes the IFU slice or 2D image array and the data quality slice to produce a masked array\n",
    "    #Identify outliers\n",
    "    \n",
    "    clean_mask = np.ones_like(data_slice)\n",
    "    rows,cols = data_slice.shape[0],data_slice.shape[1]\n",
    "    clean_slice = data_slice\n",
    "    #plt.imshow(clean_slice)\n",
    "    for row in range(0,rows):\n",
    "        for col in range(0,cols):\n",
    "            perimeter_median = np.median(data_slice[row-1:row+1,col-1:col+1])\n",
    "            if abs(data_slice[row,col]) >= abs(15*perimeter_median):\n",
    "                clean_slice[row,col] = perimeter_median\n",
    "                if abs(data_slice[row,col]) >= abs(25*perimeter_median):\n",
    "                    print('Flagged value: '+str(data_slice[row,col]))\n",
    "                    print('Replaced with: '+str(perimeter_median))\n",
    "                    clean_mask[row,col]= 0\n",
    "                    clean_slice[row,col] = perimeter_median\n",
    "    return clean_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf6b561",
   "metadata": {},
   "source": [
    "## ðŸ§­ Image Alignment and Shift Measurement\n",
    "Next let's define a function that finds the shift between images using cross-correlation, a common method for fine alignment. We make use of the Scipy.signal.correlate2d function, which minimizes the differences between images. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ab40de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_image_shift(image1, image2):\n",
    "    \"\"\"\n",
    "    Compute the best-fit alignment shift between two images using cross-correlation.\n",
    "    :param image1: First image\n",
    "    :param image2: Second image\n",
    "    :return: (dx, dy) shift required to align image2 to image1\n",
    "    \"\"\"\n",
    "    correlation = signal.correlate2d(image1, image2, boundary='symm', mode='same')\n",
    "    y_max, x_max = np.unravel_index(np.argmax(correlation), correlation.shape)\n",
    "    center_y, center_x = np.array(image1.shape) // 2\n",
    "    dy = y_max - center_y\n",
    "    dx = x_max - center_x\n",
    "    return dx, dy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f2bf4c",
   "metadata": {},
   "source": [
    "## ðŸ“Š Stack and Co-add Images\n",
    "Now we can set up our loop to work through the science images to clean, align, and stack.  This can be done with mean or median stacking.\n",
    "Median stacking is robust to outliers (e.g. cosmic rays), while mean stacking preserves photometric accuracy better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b01dc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_coadd(method = 'mean',best_fit=False,use_full=False,verbose = False,save_int = True):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    method : str, 'mean' or 'median'\n",
    "        Defines how images will be combined. The default is 'mean'.\n",
    "    best_fit : Boolean, optional\n",
    "        Toggle for if best fit routine is used to fine tune stack. The default is False.\n",
    "    use_full : Boolean, optional\n",
    "        Toggle to use full image to perform the best_fit. The default is False.\n",
    "    verbose : Boolean, optional\n",
    "        Toggle to print out intermediate informaton. The default is False.\n",
    "    save_int : Boolean, optional\n",
    "        Toggle to save intermediate image stacks. The default is True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    TYPE\n",
    "        DESCRIPTION.\n",
    "\n",
    "    '''\n",
    "    c_skycoord_list = []\n",
    "    err_list = []\n",
    "    images = []\n",
    "    if method == 'median':\n",
    "        med_bool = True\n",
    "    else:\n",
    "        med_bool = False\n",
    "    if best_fit == True:\n",
    "        #Pick a file with a WCS solution you trust here.\n",
    "        comp_data= fits.getdata('file_name_Here')\n",
    "    for i,obs in enumerate(os.listdir(location)):\n",
    "        # print(file)\n",
    "        if 'DS_Store' in obs:\n",
    "            continue\n",
    "        file = location+obs+'/'+str(obs)+'_drc_v3.fits'\n",
    "        header = fits.getheader(file,0)\n",
    "        \n",
    "        #Access the wcs_header\n",
    "        wcs_header = fits.getheader(file,1)\n",
    "        data = fits.getdata(file)\n",
    "        drz_wcs1 = WCS(wcs_header)\n",
    "        \n",
    "        #These may be different depending on the datasets. Double check\n",
    "        obs_date = header['DATE-OBS']\n",
    "        obs_time = header['TIME-OBS']\n",
    "        obs_start = header['EXPSTART']\n",
    "        obs_end = header['EXPEND']\n",
    "        \n",
    "        #define the observing time for the middle point of the observations\n",
    "        obs_obj = Time((obs_start+obs_end)/2,format='mjd',scale='utc')\n",
    "        obstime_jd = obs_obj.jd \n",
    "        print(obstime_jd)\n",
    "        \n",
    "        #Query Horizons for the orbit\n",
    "        obj = Horizons(id=record_id,id_type='smallbody',location='@hst',epochs=obstime_jd)\n",
    "        eph = obj.ephemerides()\n",
    "        \n",
    "        #Create a SkyCoord for the object at the midpoint of the observations\n",
    "        c = SkyCoord(eph['RA'][0], eph['DEC'][0], frame='icrs', unit='deg')\n",
    "        c_skycoord_list.append(c)\n",
    "        err_list.append([eph['RA_3sigma'][0],eph['DEC_3sigma'][0]])\n",
    "        cen_skycoord = SkyCoord(c.ra,c.dec,frame='icrs')\n",
    "        \n",
    "        #Clean the data if it needs it (you can also use LACosmic or somethin')\n",
    "        data_clean = clean_image(data)\n",
    "        \n",
    "        #convert the objects SkyCoord to the frame pixels\n",
    "        pix_cen = drz_wcs1.world_to_pixel(cen_skycoord)\n",
    "        pix_cen = [pix_cen[0], pix_cen[1]]\n",
    "        if best_fit == True and i >= 1:\n",
    "            #Perform iterative fitting to find best small shift to data\n",
    "            if verbose == True:\n",
    "                print('Starting alignment process for: '+str(obs))\n",
    "            #pix_cen = align_images(data_clean,images,pix_cen,obs,median = med_bool)\n",
    "            dx,dy = find_image_shift(data_clean, images)\n",
    "            pix_cen = [pix_cen[0]+dx,pix_cen[1]+dy]\n",
    "        else:\n",
    "            pix_cen = drz_wcs1.world_to_pixel(cen_skycoord)\n",
    "        x_low,x_high = int(pix_cen[0])-500,int(pix_cen[0])+500\n",
    "        y_low,y_high = int(pix_cen[1])-500,int(pix_cen[1])+500\n",
    "        \n",
    "        data_trim = data_clean[x_low:x_high,y_low:y_high]\n",
    "        #data_trim = data[int(pix_cen[0])-200:int(pix_cen[0])+200,\n",
    "        #                      int(pix_cen[1])-200:int(pix_cen[1])-200]\n",
    "        images.append(data_trim)\n",
    "        if i == 0:\n",
    "            data_og = data\n",
    "            data_sum = data_trim\n",
    "            #save a larger image for the fitting steps, centered on the best fit location for your object \n",
    "            x_low,x_high = int(pix_cen[0])-50,int(pix_cen[0])+50\n",
    "            y_low,y_high = int(pix_cen[1])-50,int(pix_cen[1])+50\n",
    "            data_trim = data_clean[x_low:x_high,y_low:y_high]\n",
    "            comp_data = data_trim\n",
    "        else:\n",
    "            data_og += data\n",
    "            data_sum += data_trim\n",
    "            if save_int == True:\n",
    "                #This saves the intermediate stack so that you can check for any mis-alignment in the process\n",
    "                output = np.median(np.array(images), axis = 0)\n",
    "                hdu_coadd = fits.PrimaryHDU(output)\n",
    "                hdu_list = fits.HDUList([hdu_coadd])\n",
    "                hdu_list.writeto('obj_img_stacked_intermediate'+str(i)+'.fits',overwrite=True)\n",
    "            if use_full == True:\n",
    "                x_low,x_high = int(pix_cen[0])-50,int(pix_cen[0])+50\n",
    "                y_low,y_high = int(pix_cen[1])-50,int(pix_cen[1])+50\n",
    "                data_trim = data_clean[x_low:x_high,y_low:y_high]\n",
    "                \n",
    "                comp_data = data_trim\n",
    "    #Save new stack to FITS file\n",
    "    hdu_coadd = fits.PrimaryHDU(data_sum/i)\n",
    "    hdu_list = fits.HDUList([hdu_coadd])\n",
    "    hdu_list.writeto('obj_img_stacked.fits',overwrite=True)\n",
    "    \n",
    "    data_med_array = np.array(images)\n",
    "    if method == 'median':\n",
    "        median = np.median(data_med_array, axis = 0)\n",
    "        hdu_median = fits.PrimaryHDU(median)\n",
    "        hdu_list = fits.HDUList([hdu_median])\n",
    "        hdu_list.writeto('obj_img_median.fits',overwrite=True)\n",
    "        plt.figure(4)\n",
    "        plt.imshow(median, vmin=0, vmax=1,cmap='viridis')\n",
    "        return median\n",
    "    elif method == 'mean':\n",
    "        mean = np.mean(data_med_array, axis = 0)\n",
    "        hdu_mean = fits.PrimaryHDU(mean)\n",
    "        hdu_list = fits.HDUList([hdu_mean])\n",
    "        hdu_list.writeto('obj_img_mean.fits',overwrite=True)\n",
    "        plt.figure(4)\n",
    "        plt.imshow(mean, vmin=0, vmax=1,cmap='viridis')\n",
    "        return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9ac840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the full stacking pipeline\n",
    "coadded_image = crop_and_coadd(method='median', verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
